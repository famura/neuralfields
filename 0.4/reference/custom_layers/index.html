<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A type of potential-based recurrent neural networks implemented with PyTorch"><meta name=author content="Fabio Muratore"><link href=https://famura.github.io/neuralfields/0.4/reference/custom_layers/ rel=canonical><link href=../ rel=prev><link href=../custom_types/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.0, mkdocs-material-9.5.28"><title>custom_layers - neuralfields</title><link rel=stylesheet href=../../assets/stylesheets/main.6543a935.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#neuralfields.custom_layers class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=neuralfields class="md-header__button md-logo" aria-label=neuralfields data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> neuralfields </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> custom_layers </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-orange data-md-color-accent=deep-orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/famura/neuralfields title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> famura/neuralfields </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Overview </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Code Reference </a> </li> <li class=md-tabs__item> <a href=../../contributing/ class=md-tabs__link> Development </a> </li> <li class=md-tabs__item> <a href=../../license/ class=md-tabs__link> License </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=neuralfields class="md-nav__button md-logo" aria-label=neuralfields data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> neuralfields </label> <div class=md-nav__source> <a href=https://github.com/famura/neuralfields title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> famura/neuralfields </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../.. class="md-nav__link "> <span class=md-ellipsis> Overview </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Overview </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../getting_started/ class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=../../exported/changelog/ class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Code Reference </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Code Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> custom_layers </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> custom_layers </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#neuralfields.custom_layers class=md-nav__link> <span class=md-ellipsis> custom_layers </span> </a> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer class=md-nav__link> <span class=md-ellipsis> IndependentNonlinearitiesLayer </span> </a> <nav class=md-nav aria-label=IndependentNonlinearitiesLayer> <ul class=md-nav__list> <li class=md-nav__item> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer.forward class=md-nav__link> <span class=md-ellipsis> forward </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.MirroredConv1d class=md-nav__link> <span class=md-ellipsis> MirroredConv1d </span> </a> <nav class=md-nav aria-label=MirroredConv1d> <ul class=md-nav__list> <li class=md-nav__item> <a href=#neuralfields.custom_layers.MirroredConv1d.forward class=md-nav__link> <span class=md-ellipsis> forward </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.apply_bell_shaped_weights_conv_ class=md-nav__link> <span class=md-ellipsis> apply_bell_shaped_weights_conv_ </span> </a> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.init_param_ class=md-nav__link> <span class=md-ellipsis> init_param_ </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../custom_types/ class=md-nav__link> <span class=md-ellipsis> custom_types </span> </a> </li> <li class=md-nav__item> <a href=../neural_fields/ class=md-nav__link> <span class=md-ellipsis> neural_fields </span> </a> </li> <li class=md-nav__item> <a href=../potential_based/ class=md-nav__link> <span class=md-ellipsis> potential_based </span> </a> </li> <li class=md-nav__item> <a href=../simple_neural_fields/ class=md-nav__link> <span class=md-ellipsis> simple_neural_fields </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Development </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Development </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../contributing/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> </a> </li> <li class=md-nav__item> <a href=../../exported/coverage/report.html class=md-nav__link> <span class=md-ellipsis> Coverage </span> </a> </li> <li class=md-nav__item> <a href=../../exported/tests/report.html class=md-nav__link> <span class=md-ellipsis> Tests </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> License </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> License </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../license/ class=md-nav__link> <span class=md-ellipsis> This Project </span> </a> </li> <li class=md-nav__item> <a href=../../exported/third_party_licenses/ class=md-nav__link> <span class=md-ellipsis> Third-Party Libraries </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#neuralfields.custom_layers class=md-nav__link> <span class=md-ellipsis> custom_layers </span> </a> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer class=md-nav__link> <span class=md-ellipsis> IndependentNonlinearitiesLayer </span> </a> <nav class=md-nav aria-label=IndependentNonlinearitiesLayer> <ul class=md-nav__list> <li class=md-nav__item> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer.forward class=md-nav__link> <span class=md-ellipsis> forward </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.MirroredConv1d class=md-nav__link> <span class=md-ellipsis> MirroredConv1d </span> </a> <nav class=md-nav aria-label=MirroredConv1d> <ul class=md-nav__list> <li class=md-nav__item> <a href=#neuralfields.custom_layers.MirroredConv1d.forward class=md-nav__link> <span class=md-ellipsis> forward </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.apply_bell_shaped_weights_conv_ class=md-nav__link> <span class=md-ellipsis> apply_bell_shaped_weights_conv_ </span> </a> </li> <li class=md-nav__item> <a href=#neuralfields.custom_layers.init_param_ class=md-nav__link> <span class=md-ellipsis> init_param_ </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>custom_layers</h1> <div class="doc doc-object doc-module"> <a id=neuralfields.custom_layers></a> <div class="doc doc-contents first"> <div class="doc doc-children"> <div class="doc doc-object doc-class"> <h2 id=neuralfields.custom_layers.IndependentNonlinearitiesLayer class="doc doc-heading"> <code class="highlight language-python"><span class=n>IndependentNonlinearitiesLayer</span><span class=p>(</span><span class=n>in_features</span><span class=p>,</span> <span class=n>nonlin</span><span class=p>,</span> <span class=n>bias</span><span class=p>,</span> <span class=n>weight</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><a class="autorefs autorefs-external" title="torch.nn.Module" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></code></p> <p>Neural network layer to add a bias, multiply the result with a scaling factor, and then apply the given nonlinearity. If a list of nonlinearities is provided, every dimension will be processed separately. The scaling and the bias are learnable parameters.</p> <div class=highlight><pre><span></span><code>nonlin: The nonlinear function to apply.
bias: If `True`, a learnable bias is subtracted, else no bias is used.
weight: If `True`, the input is multiplied with a learnable scaling factor.
</code></pre></div> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>106</span>
<span class=normal>107</span>
<span class=normal>108</span>
<span class=normal>109</span>
<span class=normal>110</span>
<span class=normal>111</span>
<span class=normal>112</span>
<span class=normal>113</span>
<span class=normal>114</span>
<span class=normal>115</span>
<span class=normal>116</span>
<span class=normal>117</span>
<span class=normal>118</span>
<span class=normal>119</span>
<span class=normal>120</span>
<span class=normal>121</span>
<span class=normal>122</span>
<span class=normal>123</span>
<span class=normal>124</span>
<span class=normal>125</span>
<span class=normal>126</span>
<span class=normal>127</span>
<span class=normal>128</span>
<span class=normal>129</span>
<span class=normal>130</span>
<span class=normal>131</span>
<span class=normal>132</span>
<span class=normal>133</span>
<span class=normal>134</span>
<span class=normal>135</span>
<span class=normal>136</span>
<span class=normal>137</span>
<span class=normal>138</span>
<span class=normal>139</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
    <span class=bp>self</span><span class=p>,</span>
    <span class=n>in_features</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
    <span class=n>nonlin</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=n>ActivationFunction</span><span class=p>,</span> <span class=n>Sequence</span><span class=p>[</span><span class=n>ActivationFunction</span><span class=p>]],</span>
    <span class=n>bias</span><span class=p>:</span> <span class=nb>bool</span><span class=p>,</span>
    <span class=n>weight</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
<span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Args:</span>
<span class=sd>        in_features: Number of dimensions of each input sample.</span>
<span class=sd>        nonlin: The nonlinear function to apply.</span>
<span class=sd>        bias: If `True`, a learnable bias is subtracted, else no bias is used.</span>
<span class=sd>        weight: If `True`, the input is multiplied with a learnable scaling factor.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=nb>callable</span><span class=p>(</span><span class=n>nonlin</span><span class=p>):</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>nonlin</span><span class=p>)</span> <span class=o>!=</span> <span class=n>in_features</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span>
                <span class=sa>f</span><span class=s2>&quot;Either one, or </span><span class=si>{</span><span class=n>in_features</span><span class=si>}</span><span class=s2> nonlinear functions have been expected, but &quot;</span>
                <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>nonlin</span><span class=p>)</span><span class=si>}</span><span class=s2> have been given!&quot;</span>
            <span class=p>)</span>

    <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

    <span class=c1># Create and initialize the parameters, and the activation function.</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>nonlin</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>nonlin</span><span class=p>)</span> <span class=k>if</span> <span class=n>_is_iterable</span><span class=p>(</span><span class=n>nonlin</span><span class=p>)</span> <span class=k>else</span> <span class=n>nonlin</span>
    <span class=k>if</span> <span class=n>weight</span><span class=p>:</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=n>in_features</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>get_default_dtype</span><span class=p>()),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=k>if</span> <span class=n>bias</span><span class=p>:</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=n>in_features</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>get_default_dtype</span><span class=p>()),</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=n>init_param_</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=neuralfields.custom_layers.IndependentNonlinearitiesLayer.forward class="doc doc-heading"> <code class="highlight language-python"><span class=n>forward</span><span class=p>(</span><span class=n>inp</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.IndependentNonlinearitiesLayer.forward class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Apply a bias, scaling, and a nonliterary to each input separately.</p> <p><span class=arithmatex>\(y = f_{nlin}( w * (x + b) )\)</span></p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>inp</code></td> <td> <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code> </td> <td> <div class=doc-md-description> <p>Arbitrary input tensor.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code> </td> <td> <div class=doc-md-description> <p>Output tensor.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>144</span>
<span class=normal>145</span>
<span class=normal>146</span>
<span class=normal>147</span>
<span class=normal>148</span>
<span class=normal>149</span>
<span class=normal>150</span>
<span class=normal>151</span>
<span class=normal>152</span>
<span class=normal>153</span>
<span class=normal>154</span>
<span class=normal>155</span>
<span class=normal>156</span>
<span class=normal>157</span>
<span class=normal>158</span>
<span class=normal>159</span>
<span class=normal>160</span>
<span class=normal>161</span>
<span class=normal>162</span>
<span class=normal>163</span>
<span class=normal>164</span>
<span class=normal>165</span>
<span class=normal>166</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inp</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Apply a bias, scaling, and a nonliterary to each input separately.</span>

<span class=sd>    $y = f_{nlin}( w * (x + b) )$</span>

<span class=sd>    Args:</span>
<span class=sd>        inp: Arbitrary input tensor.</span>

<span class=sd>    Returns:</span>
<span class=sd>        Output tensor.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Add bias if desired.</span>
    <span class=n>tmp</span> <span class=o>=</span> <span class=n>inp</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>inp</span>

    <span class=c1># Apply weights if desired.</span>
    <span class=n>tmp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>*</span> <span class=n>tmp</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>tmp</span>

    <span class=c1># Every dimension runs through an individual nonlinearity.</span>
    <span class=k>if</span> <span class=n>_is_iterable</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>nonlin</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>fcn</span><span class=p>(</span><span class=n>tmp</span><span class=p>[</span><span class=n>idx</span><span class=p>])</span> <span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=n>fcn</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>nonlin</span><span class=p>)])</span>

    <span class=c1># All dimensions identically.</span>
    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>nonlin</span><span class=p>(</span><span class=n>tmp</span><span class=p>)</span>  <span class=c1># type: ignore[operator]</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=neuralfields.custom_layers.MirroredConv1d class="doc doc-heading"> <code class="highlight language-python"><span class=n>MirroredConv1d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=s1>&#39;same&#39;</span><span class=p>,</span> <span class=n>dilation</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>groups</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>padding_mode</span><span class=o>=</span><span class=s1>&#39;zeros&#39;</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.MirroredConv1d class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title="torch.nn.modules.conv._ConvNd">_ConvNd</span></code></p> <p>A variant of the <a class="autorefs autorefs-external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d</a> module that re-uses parts of the convolution weights by mirroring the first half of the kernel (along the columns). This way we can save almost half of the parameters, under the assumption that we have a kernel that obeys this kind of symmetry. The biases are left unchanged.</p> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>175</span>
<span class=normal>176</span>
<span class=normal>177</span>
<span class=normal>178</span>
<span class=normal>179</span>
<span class=normal>180</span>
<span class=normal>181</span>
<span class=normal>182</span>
<span class=normal>183</span>
<span class=normal>184</span>
<span class=normal>185</span>
<span class=normal>186</span>
<span class=normal>187</span>
<span class=normal>188</span>
<span class=normal>189</span>
<span class=normal>190</span>
<span class=normal>191</span>
<span class=normal>192</span>
<span class=normal>193</span>
<span class=normal>194</span>
<span class=normal>195</span>
<span class=normal>196</span>
<span class=normal>197</span>
<span class=normal>198</span>
<span class=normal>199</span>
<span class=normal>200</span>
<span class=normal>201</span>
<span class=normal>202</span>
<span class=normal>203</span>
<span class=normal>204</span>
<span class=normal>205</span>
<span class=normal>206</span>
<span class=normal>207</span>
<span class=normal>208</span>
<span class=normal>209</span>
<span class=normal>210</span>
<span class=normal>211</span>
<span class=normal>212</span>
<span class=normal>213</span>
<span class=normal>214</span>
<span class=normal>215</span>
<span class=normal>216</span>
<span class=normal>217</span>
<span class=normal>218</span>
<span class=normal>219</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
    <span class=bp>self</span><span class=p>,</span>
    <span class=n>in_channels</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
    <span class=n>out_channels</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
    <span class=n>kernel_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
    <span class=n>stride</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>
    <span class=n>padding</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&quot;same&quot;</span><span class=p>,</span>  <span class=c1># kernel_size // 2 if padding_mode != &quot;circular&quot; else kernel_size - 1</span>
    <span class=n>dilation</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>
    <span class=n>groups</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>
    <span class=n>bias</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
    <span class=n>padding_mode</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;zeros&quot;</span><span class=p>,</span>
    <span class=n>device</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Union</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
    <span class=n>dtype</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<span class=p>):</span>
    <span class=c1># Same as in PyTorch 1.12.</span>
    <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span>
        <span class=n>in_channels</span><span class=o>=</span><span class=n>in_channels</span><span class=p>,</span>
        <span class=n>out_channels</span><span class=o>=</span><span class=n>out_channels</span><span class=p>,</span>
        <span class=n>kernel_size</span><span class=o>=</span><span class=n>_single</span><span class=p>(</span><span class=n>kernel_size</span><span class=p>),</span>  <span class=c1># type: ignore[arg-type]</span>
        <span class=n>stride</span><span class=o>=</span><span class=n>_single</span><span class=p>(</span><span class=n>stride</span><span class=p>),</span>  <span class=c1># type: ignore[arg-type]</span>
        <span class=n>padding</span><span class=o>=</span><span class=n>_single</span><span class=p>(</span><span class=n>padding</span><span class=p>)</span> <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>padding</span><span class=p>,</span> <span class=nb>str</span><span class=p>)</span> <span class=k>else</span> <span class=n>padding</span><span class=p>,</span>  <span class=c1># type: ignore[arg-type]</span>
        <span class=n>dilation</span><span class=o>=</span><span class=n>_single</span><span class=p>(</span><span class=n>dilation</span><span class=p>),</span>  <span class=c1># type: ignore[arg-type]</span>
        <span class=n>transposed</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
        <span class=n>output_padding</span><span class=o>=</span><span class=n>_single</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span>
        <span class=n>groups</span><span class=o>=</span><span class=n>groups</span><span class=p>,</span>
        <span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>,</span>
        <span class=n>padding_mode</span><span class=o>=</span><span class=n>padding_mode</span><span class=p>,</span>
        <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>,</span>
        <span class=n>dtype</span><span class=o>=</span><span class=n>dtype</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=c1># Memorize PyTorch&#39;s weight shape (out_channels x in_channels x kernel_size) for later reconstruction.</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>shape</span>

    <span class=c1># Get number of kernel elements we later want to use for mirroring.</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>half_kernel_size</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>)</span>  <span class=c1># kernel_size = 4 --&gt; 2, kernel_size = 5 --&gt; 3</span>

    <span class=c1># Initialize the weights values the same way PyTorch does.</span>
    <span class=n>new_weight_init</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>half_kernel_size</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span>
    <span class=p>)</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_uniform_</span><span class=p>(</span><span class=n>new_weight_init</span><span class=p>,</span> <span class=n>a</span><span class=o>=</span><span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>

    <span class=c1># Overwrite the weight attribute (transposed is False by default for the Conv1d module, we don&#39;t use it here).</span>
    <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>new_weight_init</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=neuralfields.custom_layers.MirroredConv1d.forward class="doc doc-heading"> <code class="highlight language-python"><span class=n>forward</span><span class=p>(</span><span class=n>inp</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.MirroredConv1d.forward class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Computes the 1-dim convolution just like <a class="autorefs autorefs-external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d</a>, however, the kernel has mirrored weights, i.e., it is symmetric around its middle element, or in case of an even kernel size around an imaginary middle element.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>inp</code></td> <td> <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code> </td> <td> <div class=doc-md-description> <p>3-dim input tensor just like for <a class="autorefs autorefs-external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d</a>.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code> </td> <td> <div class=doc-md-description> <p>3-dim output tensor just like for <a class="autorefs autorefs-external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d</a>.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>221</span>
<span class=normal>222</span>
<span class=normal>223</span>
<span class=normal>224</span>
<span class=normal>225</span>
<span class=normal>226</span>
<span class=normal>227</span>
<span class=normal>228</span>
<span class=normal>229</span>
<span class=normal>230</span>
<span class=normal>231</span>
<span class=normal>232</span>
<span class=normal>233</span>
<span class=normal>234</span>
<span class=normal>235</span>
<span class=normal>236</span>
<span class=normal>237</span>
<span class=normal>238</span>
<span class=normal>239</span>
<span class=normal>240</span>
<span class=normal>241</span>
<span class=normal>242</span>
<span class=normal>243</span>
<span class=normal>244</span>
<span class=normal>245</span>
<span class=normal>246</span>
<span class=normal>247</span>
<span class=normal>248</span>
<span class=normal>249</span>
<span class=normal>250</span>
<span class=normal>251</span>
<span class=normal>252</span>
<span class=normal>253</span>
<span class=normal>254</span>
<span class=normal>255</span>
<span class=normal>256</span>
<span class=normal>257</span></pre></div></td><td class=code><div><pre><span></span><code><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inp</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Computes the 1-dim convolution just like [Conv1d][torch.nn.Conv1d], however, the kernel has mirrored weights,</span>
<span class=sd>    i.e., it is symmetric around its middle element, or in case of an even kernel size around an imaginary middle</span>
<span class=sd>    element.</span>

<span class=sd>    Args:</span>
<span class=sd>        inp: 3-dim input tensor just like for [Conv1d][torch.nn.Conv1d].</span>

<span class=sd>    Returns:</span>
<span class=sd>        3-dim output tensor just like for [Conv1d][torch.nn.Conv1d].</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Reconstruct symmetric weights for convolution (original size).</span>
    <span class=n>mirr_weight</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>inp</span><span class=o>.</span><span class=n>dtype</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>

    <span class=c1># Loop over input channels.</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]):</span>
        <span class=c1># Fill first half.</span>
        <span class=n>mirr_weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>half_kernel_size</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:]</span>

        <span class=c1># Fill second half (flip columns left-right).</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>orig_weight_shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
            <span class=c1># Odd kernel size for convolution, don&#39;t flip the last column.</span>
            <span class=n>mirr_weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>half_kernel_size</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flip</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:],</span> <span class=p>(</span><span class=mi>1</span><span class=p>,))[:,</span> <span class=mi>1</span><span class=p>:]</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># Even kernel size for convolution, flip all columns.</span>
            <span class=n>mirr_weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>half_kernel_size</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flip</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=p>[:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:],</span> <span class=p>(</span><span class=mi>1</span><span class=p>,))</span>

    <span class=c1># Run through the same function as the original PyTorch implementation, but with mirrored kernel.</span>
    <span class=k>return</span> <span class=n>F</span><span class=o>.</span><span class=n>conv1d</span><span class=p>(</span>
        <span class=nb>input</span><span class=o>=</span><span class=n>inp</span><span class=p>,</span>
        <span class=n>weight</span><span class=o>=</span><span class=n>mirr_weight</span><span class=p>,</span>
        <span class=n>bias</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>bias</span><span class=p>,</span>
        <span class=n>stride</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>stride</span><span class=p>,</span>
        <span class=n>padding</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>padding</span><span class=p>,</span>
        <span class=n>dilation</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>dilation</span><span class=p>,</span>
        <span class=n>groups</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>groups</span><span class=p>,</span>
    <span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-function"> <h2 id=neuralfields.custom_layers.apply_bell_shaped_weights_conv_ class="doc doc-heading"> <code class="highlight language-python"><span class=n>apply_bell_shaped_weights_conv_</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>ks</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.apply_bell_shaped_weights_conv_ class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p>Helper function to set the weights of a convolution layer according to a squared exponential.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>m</code></td> <td> <code><a class="autorefs autorefs-external" title="torch.nn.Module" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></code> </td> <td> <div class=doc-md-description> <p>Module containing the weights to be set.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td><code>w</code></td> <td> <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code> </td> <td> <div class=doc-md-description> <p>Linearly spaced weights.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td><code>ks</code></td> <td> <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code> </td> <td> <div class=doc-md-description> <p>Size of the convolution kernel.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span></pre></div></td><td class=code><div><pre><span></span><code><span class=nd>@torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span>
<span class=k>def</span> <span class=nf>apply_bell_shaped_weights_conv_</span><span class=p>(</span><span class=n>m</span><span class=p>:</span> <span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>w</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>ks</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Helper function to set the weights of a convolution layer according to a squared exponential.</span>

<span class=sd>    Args:</span>
<span class=sd>        m: Module containing the weights to be set.</span>
<span class=sd>        w: Linearly spaced weights.</span>
<span class=sd>        ks: Size of the convolution kernel.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>dim_ch_out</span><span class=p>,</span> <span class=n>dim_ch_in</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># type: ignore[operator]</span>
    <span class=n>amp</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>dim_ch_out</span> <span class=o>*</span> <span class=n>dim_ch_in</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>dim_ch_out</span><span class=p>):</span>
        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>dim_ch_in</span><span class=p>):</span>
            <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>amp</span><span class=p>[</span><span class=n>i</span> <span class=o>*</span> <span class=n>dim_ch_in</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>torch</span><span class=o>.</span><span class=n>pow</span><span class=p>(</span><span class=n>w</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>ks</span> <span class=o>/</span> <span class=mi>2</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h2 id=neuralfields.custom_layers.init_param_ class="doc doc-heading"> <code class="highlight language-python"><span class=n>init_param_</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span></code> <a href=#neuralfields.custom_layers.init_param_ class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p>Initialize the parameters of the PyTorch Module / layer / network / cell according to its type.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>m</code></td> <td> <code><a class="autorefs autorefs-external" title="torch.nn.Module" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">Module</a></code> </td> <td> <div class=doc-md-description> <p>Module containing the weights to be set.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td><code>kwargs</code></td> <td> <code><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></code> </td> <td> <div class=doc-md-description> <p>Optional keyword arguments, e.g. <code>bell=True</code> to initialize a convolution layer's weight with a centered "bell-shaped" parameter value distribution.</p> </div> </td> <td> <code>{}</code> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>neuralfields/custom_layers.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>47</span>
<span class=normal>48</span>
<span class=normal>49</span>
<span class=normal>50</span>
<span class=normal>51</span>
<span class=normal>52</span>
<span class=normal>53</span>
<span class=normal>54</span>
<span class=normal>55</span>
<span class=normal>56</span>
<span class=normal>57</span>
<span class=normal>58</span>
<span class=normal>59</span>
<span class=normal>60</span>
<span class=normal>61</span>
<span class=normal>62</span>
<span class=normal>63</span>
<span class=normal>64</span>
<span class=normal>65</span>
<span class=normal>66</span>
<span class=normal>67</span>
<span class=normal>68</span>
<span class=normal>69</span>
<span class=normal>70</span>
<span class=normal>71</span>
<span class=normal>72</span>
<span class=normal>73</span>
<span class=normal>74</span>
<span class=normal>75</span>
<span class=normal>76</span>
<span class=normal>77</span>
<span class=normal>78</span>
<span class=normal>79</span>
<span class=normal>80</span>
<span class=normal>81</span>
<span class=normal>82</span>
<span class=normal>83</span>
<span class=normal>84</span>
<span class=normal>85</span>
<span class=normal>86</span>
<span class=normal>87</span>
<span class=normal>88</span>
<span class=normal>89</span>
<span class=normal>90</span>
<span class=normal>91</span>
<span class=normal>92</span>
<span class=normal>93</span>
<span class=normal>94</span></pre></div></td><td class=code><div><pre><span></span><code><span class=nd>@torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span>
<span class=k>def</span> <span class=nf>init_param_</span><span class=p>(</span><span class=n>m</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>:</span> <span class=n>Any</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Initialize the parameters of the PyTorch Module / layer / network / cell according to its type.</span>

<span class=sd>    Args:</span>
<span class=sd>        m: Module containing the weights to be set.</span>
<span class=sd>        kwargs: Optional keyword arguments, e.g. `bell=True` to initialize a convolution layer&#39;s weight with a</span>
<span class=sd>            centered &quot;bell-shaped&quot; parameter value distribution.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>kwargs</span> <span class=o>=</span> <span class=n>kwargs</span> <span class=k>if</span> <span class=n>kwargs</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=nb>dict</span><span class=p>()</span>

    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv1d</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;bell&quot;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
            <span class=c1># Initialize the kernel weights with a shifted of shape exp(-x^2 / sigma^2).</span>
            <span class=c1># The biases are left unchanged.</span>
            <span class=k>if</span> <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
                <span class=n>ks_half</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span>
                <span class=n>ls_half</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>ks_half</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ks_half</span><span class=p>)</span>  <span class=c1># descending</span>
                <span class=n>ls</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>ls_half</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>flip</span><span class=p>(</span><span class=n>ls_half</span><span class=p>,</span> <span class=p>(</span><span class=mi>0</span><span class=p>,))])</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>ks_half</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>)</span>
                <span class=n>ls_half</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>ks_half</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ks_half</span><span class=p>)</span>  <span class=c1># descending</span>
                <span class=n>ls</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>ls_half</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>flip</span><span class=p>(</span><span class=n>ls_half</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=p>(</span><span class=mi>0</span><span class=p>,))])</span>
            <span class=n>apply_bell_shaped_weights_conv_</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>ls</span><span class=p>,</span> <span class=n>ks_half</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>m</span><span class=o>.</span><span class=n>reset_parameters</span><span class=p>()</span>

    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>MirroredConv1d</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;bell&quot;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
            <span class=c1># Initialize the kernel weights with a shifted of shape exp(-x^2 / sigma^2).</span>
            <span class=c1># The biases are left unchanged (does not exist by default).</span>
            <span class=n>ks</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># ks_mirr = ceil(ks_conv1d / 2)</span>
            <span class=n>ls</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>ks</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ks</span><span class=p>)</span>  <span class=c1># descending</span>
            <span class=n>apply_bell_shaped_weights_conv_</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>ls</span><span class=p>,</span> <span class=n>ks</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>m</span><span class=o>.</span><span class=n>reset_parameters</span><span class=p>()</span>

    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>IndependentNonlinearitiesLayer</span><span class=p>):</span>
        <span class=c1># Initialize the network&#39;s parameters according to a normal distribution.</span>
        <span class=k>for</span> <span class=n>tensor</span> <span class=ow>in</span> <span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>tensor</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>1.0</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>tensor</span><span class=o>.</span><span class=n>nelement</span><span class=p>()))</span>

    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;self_centric_init&quot;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
            <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>fill_</span><span class=p>(</span><span class=o>-</span><span class=mf>0.5</span><span class=p>)</span>  <span class=c1># inhibit others</span>
            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)):</span>
                <span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.0</span>  <span class=c1># excite self</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">July 9, 2024</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["header.autohide", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.top", "search.highlight", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.fe8b6f2b.min.js></script> <script src=https://unpkg.com/tablesort/dist/tablesort.min.js></script> <script src=../../js/tablesort.js></script> <script src=../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>